{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02477 Bayesian machine learning - Exercise 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miri/anaconda3/envs/ATEL/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as snb\n",
    "\n",
    "snb.set_style('darkgrid')\n",
    "snb.set(font_scale=1.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to become familiar with variational inference and to demystify the calculations involved.\n",
    "\n",
    "In this exercise, we will analyze a very simple Bayesian model in two ways. First, we will derive the exact posterior distribution and the exact marginal likelihood analytically. Next, we derive a variational approximation and compare the approximate results to the exact results. This also provides an opportunity the practice some of the basic concepts of probabilistic calculations, i.e. manipulating distribution using the sum and product rules.\n",
    "\n",
    "\n",
    "The exercise is divided into 4 parts:\n",
    "\n",
    "- Part 0: Motivation for the choice of toy example\n",
    "\n",
    "\n",
    "- Part 1: Exact inference\n",
    "\n",
    "\n",
    "- Part 2: Variational inference and CAVI updates\n",
    "\n",
    "\n",
    "- Part 3: The lower bound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Motivation for the toy example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In statistics and machine learning, a **sparse** vector is a vector, where the majority of its entries is exactly equal to zero. For example, \n",
    "\n",
    "$$\\mathbf{x} = \\begin{bmatrix} 0 & 0 & 2.3 & 0 & 4.7 & 0 & 0\\end{bmatrix}$$\n",
    "\n",
    "is a sparse vector.  **Sparsity** is a very efficient tool for tackling high-dimensional problems. Assuming sparsity often allows us to solve high-dimensional regression problems, where the number of features $D$ is much larger than then number of observations $N$, i.e. $D \\gg N$. Informally, this works because the sparsity mechanism allows the models to ignore irrelevant or noisy features automatically. Sparsity can also play a key role in interpretability.\n",
    "\n",
    "In classical machine learning, $\\ell_1$-regularization (LASSO) is a common way to introduce sparsity. In the Bayesian world, there are several ways to model sparsity, incl. **automatic relevance determination**, **Horseshoe priors** and **spike-and-slab priors**.\n",
    "\n",
    "The so-called spike-and-slab prior is very easy to understand from a generative perspective. Suppose we impose such a prior distribution on a parameter $w$, then the generative process goes as follows:\n",
    "\n",
    "1. We \"flip a coin\" with probability $p_0$ to determine whether our parameter $w$ is zero ($s = 0$) or non-zero ($s = 1$):\n",
    "\n",
    "$$s \\sim \\text{Ber}(p_0)$$\n",
    "\n",
    "2. If it turns out to be non-zero ($s =1$), we sample the coefficient from a Gaussian (or another distributions).\n",
    "\n",
    "$$w \\sim \\mathcal{N}(0, 1)$$\n",
    "\n",
    "3. We define the parameter $\\tilde{w}$ as\n",
    "\n",
    "$$\\tilde{w} = s \\cdot w$$\n",
    "\n",
    "This process forces $w$ to be exactly zero if $s = 0$ irregardless of the value of $w$.\n",
    "\n",
    "This prior is called the spike-and-slab prior because the marginal distribution of $w$ is a mixture of a \"spike\" at $\\tilde{w} = 0$ and a Gaussian (the slab). \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exact inference in a toy example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with a very simple toy model with a Gaussian likelihood and a spike-and-slab prior on the mean of the Gaussian. Let $t \\in \\mathbb{R}$ be an observation, let $s \\in \\left\\lbrace 0, 1 \\right\\rbrace$ be a binary variable and let $w \\in \\mathbb{R}$ be a parameter, then\n",
    "\n",
    "$$\\begin{align*}\n",
    "t = s\\cdot w + e,\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $e \\sim \\mathcal{N}(0, \\sigma^2)$ is additive Gaussian noise. Here the binary variable $s \\in \\left\\lbrace 0, 1\\right\\rbrace$ indicates whether the parameter $w$ is \"active\" or not:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "t|s=0 &\\sim \\mathcal{N}(0, \\sigma^2)\\\\\n",
    "t|s=1 &\\sim \\mathcal{N}(w, \\sigma^2)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In other words, $s$ dictates whether the recorded observation $t$ is generated by signal + noise, i.e. $t = w + e$, or by pure noise, i.e. $t = e$. Assuming a Gaussian prior on $w$ and a Bernoulli prior on $s$, we can write the joint model as follows\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(t, s, w) &= p(t|s, w)p(s)p(w)\\\\\n",
    "&= \\mathcal{N}(t|sw, \\sigma^2)\\text{Ber}(s|p_0)\\mathcal{N}(w|0, \\kappa^2)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Note that the model only contains a single observation $t$, i.e. $N = 1$. We can easily extend it and the all results to $N$ observations, but we stick to $N = 1$ to keep to derivations simple as possible.\n",
    "\n",
    "\n",
    "In this exercise, we will focus on the marginal posterior $p(s|t)$, which can be interpreted as the probability of the parameter $w$ is \"active\", i.e. non-zero, after seeing the data. This quantity is therefore often used for feature and model selection. \n",
    "\n",
    "As usual, we obtain the joint posterior from Bayes' rule\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(w, s|t) = \\frac{p(t|s, w)p(s)p(w)}{p(t)}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We can easily obtain the marginal posterior $p(s|t)$ from the joint posterior, but first, we will deal with the marginal likelihood $p(t)$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1: The marginal likelihood\n",
    "\n",
    "Because this model is very simple, we can derive the normalization constant, i.e. $p(t)$, in closed form by applying the sum rule to marginalize over $s$ and $w$.\n",
    "\n",
    "**Task 1:** Show that the marginal likelihood $p(t)$ is given by\n",
    "\n",
    "$$p(t) =  (1-p_0)\\mathcal{N}(t|0, \\sigma^2) + p_0\\mathcal{N}(t|0, \\sigma^2 + \\kappa^2)\\tag{1}$$\n",
    "\n",
    "\n",
    "*Hints*\n",
    "1. The marginal distribution $p(t)$ can be obtained from the joint distribution $p(t, s, w$) by marginalizing over $s$ and $w$.\n",
    "2. The following integral $\\int \\mathcal{N}(t|sw, \\sigma^2)\\mathcal{N}(w|0, \\kappa^2) \\text{d}w = \\mathcal{N}(t|0, \\sigma^2 + s^2 \\kappa^2)$ will be useful. It is follows from eq. (2.115) in Bishop.\n",
    "3. Don't hesitate to ask for help if you are stuck.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2: The marginal posterior p(s|t)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will derive the joint posterior $p(w, s|t)$ using Bayes rule\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(w, s|t) &= \\frac{p(t|s, w)p(s)p(w)}{p(t)}\\\\\n",
    "&= \\frac{\\mathcal{N}(t|sw, \\sigma^2)\\text{Ber}(s|p_0)\\mathcal{N}(w|0, \\kappa^2)}{(1-p_0)\\mathcal{N}(t|0, \\sigma^2) + p_0\\mathcal{N}(t|0, \\sigma^2 + \\kappa^2)} \\\\\n",
    "&= \\frac{\\mathcal{N}(t|sw, \\sigma^2)\\text{Ber}(s|p_0)\\mathcal{N}(w|0, \\kappa^2)}{Z_t}, \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where we have defined $Z_t \\equiv (1-p_0)\\mathcal{N}(t|0, \\sigma^2) + p_0\\mathcal{N}(t|0, \\sigma^2 + \\kappa^2)$ to ease the notation.\n",
    "\n",
    "\n",
    "Once we have the joint posterior, we can easily compute the marginal posterior $p(s|t)$ by marginalizing over $w$ in $p(w, s|t)$\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "p(s|t) &= \\int \\frac{\\mathcal{N}(t|sw, \\sigma^2)\\text{Ber}(s|p_0)\\mathcal{N}(w|0, \\kappa^2)}{Z_t} \\text{d}w\\\\\n",
    "%\n",
    "&= \\frac{\\int  \\mathcal{N}(t|sw, \\sigma^2)\\mathcal{N}(w|0, \\kappa^2)\\text{d}w \\,\\text{Ber}(s|p_0)}{Z_t}\\\\\n",
    "%\n",
    "&= \\frac{\\mathcal{N}(t|0, \\sigma^2 + s^2 \\kappa^2) \\text{Ber}(s|p_0)}{Z_t}\\tag{a}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "where we have used eq. $(2.115)$ again in the last line. We could obtain $p(w|t)$ in a similar fashion by marginalizing over $s$ in $p(w, s|t)$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Task 2**: Use the equation above to argue that the posterior probability $p(s=1|t)$ is given by:\n",
    "\n",
    "$$ p(s=1|t) =\\frac{ p_0\\mathcal{N}(t|0, \\sigma^2 + \\kappa^2)}{Z_t}$$\n",
    "\n",
    "*Hints*\n",
    "1. This is meant to be a very easy and straight-forward question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3: Visualizing the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming $\\sigma^2 = 0.1$ and $\\kappa^2 = 1$, let's visualize $p(s=1|t)$ as a function of $t$ for various values of $p_0$\n",
    "\n",
    "**Task 3**: Plot $p(s=1|t)$ as a function of $t \\in \\left[-3, 3 \\right]$ for the following three different values of $p_0 \\in \\left\\lbrace 0.1, 0.5, 0.9 \\right\\rbrace$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-55f9eb6a66e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# values for t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mt_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# fixed hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# definition of Bernoulli and Gaussian distributions\n",
    "npdf = lambda x, m, v: np.exp(-(x-m)**2/(2*v))/np.sqrt(2*np.pi*v)\n",
    "ber = lambda s, p: p**s*(1-p)**(1-s)\n",
    "\n",
    "# values for t\n",
    "t_grid = np.linspace(-3, 3, 100)\n",
    "\n",
    "# fixed hyperparameters\n",
    "kappa2 = 1\n",
    "sigma2 = 0.1\n",
    "\n",
    "##################################################################################\n",
    "# Solution to task 3\n",
    "##################################################################################\n",
    "# ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "1) What happens to the posterior $p(s|t)$ probability as $|t|$ increases? Use the model equation $t = s\\cdot w + e$ to explain why this make sense. *Hint: Which values to we expect for $t$ when $s=0$?*\n",
    "\n",
    "2) What happens when $p_0$ is decreased? and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Variational inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will now set-up a variational approximation $q(s,w)$ to approximate the posterior distribution $p(s, w|t) \\approx q(s,w)$. We will use the following factorized variational family\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "q(s, w) = q(s)q(w) = \\text{Ber}(s|\\hat{p}) \\mathcal{N}(w|\\hat{m}, \\hat{v})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "We now assume that the $s$ and $w$ are independent in the posterior and that the posterior distributions of $s$ and $w$ are a Bernoulli distribution (with parameter $\\hat{p}$) and a Gaussian distribution (with parameters $\\hat{m}$ and $\\hat{v}$), respectively. Thus, the task of searching for a 'good' approximation is reduced to searching for a good set of **variational parameters** $(\\hat{p}, \\hat{m}, \\hat{v})$.\n",
    "\n",
    "Our goal is to identify the distribution $q(s, w|\\hat{p}, \\hat{m}, \\hat{v})$ that minimizes the KL-divergence between the exact posterior $p(s,w|t)$ and the approximation. Thus, given some observation $t$, we want to determine the variational parameters $\\hat{p}$, $\\hat{m}$, and $\\hat{v}$. \n",
    "\n",
    "In general, we can find the optimal approximation (as measured by the KL divergence) by maximizing the **evidence lowerbound** (ELBO) $\\mathcal{L}(q)$\n",
    "\n",
    "$$\\mathcal{L}(q) = \\mathbb{E}_q\\left[\\ln p(t, s, w)\\right] - \\mathbb{E}_q\\left[\\ln q(s, w)\\right]$$\n",
    "\n",
    "wrt. the variational parameters $\\hat{m}$, $\\hat{v}$ and $\\hat{p}$. \n",
    "\n",
    "However for factorized variational families, we can determine the optimal approximation for $q^*(s)$ and $q^*(w)$ using the following equations (as discussed in lecture 9 and in Sec. 10.1. in Bishop)\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\ln q^* (w) &= \\mathbb{E}_{q(s)}\\left[ \\ln \\left(p(t|s, w)p(s)p(w)\\right)\\right] + K_w\\\\\n",
    "\\ln q^*(s) &= \\mathbb{E}_{q(w)}\\left[ \\ln \\left(p(t|s, w)p(s)p(w)\\right)\\right] + K_s,\n",
    "\\end{align*}\n",
    "$$\n",
    "where $K_w$ and $K_s$ are constants.\n",
    "\n",
    "We will now go through these calculations in details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: Optimal distribution for $q(w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our starting point is the equation for $\\ln q^* (w)$. Similar to the derivation of the Gibbs sampler in exercise 8, we focus on terms that depends on $w$ and absorb the rest an the additive constant. Let's plug in the model distributions and simplify:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\ln q^* (w) &= \\mathbb{E}_{q(s)}\\left[ \\ln p(t|s, w)p(s)p(w)\\right] + K\\\\\n",
    "&=  \\mathbb{E}_{q(s)}\\left[\\ln \\mathcal{N}(t|sw, \\sigma^2)\\text{Ber}(s|p_0)\\mathcal{N}(w|0, \\kappa^2)\\right] + K\\\\\n",
    "&=  \\mathbb{E}_{q(s)}\\left[\\ln \\mathcal{N}(t|sw, \\sigma^2)\\right] + \\mathbb{E}_{q(s)}\\left[ \\ln \\text{Ber}(s|p_0)\\right] + \\mathbb{E}_{q(s)}\\left[ \\ln \\mathcal{N}(w|0, \\kappa^2)\\right] +K\\\\\n",
    "&=  \\mathbb{E}_{q(s)}\\left[\\ln \\mathcal{N}(t|sw, \\sigma^2)\\right] +  \\ln \\mathcal{N}(w|0, \\kappa^2) + K' \\tag{4}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "where we have absorbed the term $ \\mathbb{E}_{q(s)}\\left[ \\ln \\text{Ber}(s|p_0)\\right]$ into the constant because it is independent of $w$. We also used the fact that $\\ln \\mathcal{N}(w|0, \\kappa^2)$ is independet of $q(s)$.\n",
    "\n",
    "***Task 4***: For $q(z) = \\text{Ber}(z|\\hat{p})$, show that $\\mathbb{E}_q\\left[z\\right] = \\hat{p}$ and $\\mathbb{E}_q\\left[z^2\\right] = \\hat{p}$.\n",
    "\n",
    "*Hint*: The definition of the $n$-th moment of discrete random variable with distribution $p$ is $\\mathbb{E}_p\\left[z^n\\right] = \\sum_{z} z^n p(z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Task 5**: Insert the expressions for the Gaussian densities into eq. (4) and show that it simplifies to\n",
    "\n",
    "\n",
    "$$\n",
    "\\ln q^* (w) = - \\frac{1}{2} \\left[\\frac{1}{\\sigma^2}\\hat{p} +  \\frac{1}{\\kappa^2}\\right] w^2 + \\frac{1}{\\sigma^2} \\hat{p} t w  + K' \\tag{5}\n",
    "$$\n",
    "\n",
    "*Hints:*\n",
    "1. Absorb all terms independent of $w$ into the constant (e.g. normalization terms from the Gaussian densities)\n",
    "2. Remember that expectations are linear\n",
    "3. The results of task 4 will come in handy\n",
    "4. Collect all terms that depends on $w^2$ and collect all terms that depends on $w$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection of eq. (5), we recognize the functional form of $\\ln q(w)$ as a quadratic function of $w$ and thus, we conclude that $q(w)$ must be a Gaussian distribution. (We already made that assumption, but now we proved that it is optimal)\n",
    "\n",
    "\n",
    "Consider the log density for a generic Gaussian distribution with mean $m$ and variance $v$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\ln \\mathcal{N}(w|m,v) &= -\\frac{1}{2}\\log(2\\pi v) -\\frac{1}{2v}(w-m)^2\\\\\n",
    "&= -\\frac{1}{2v}(w^2 + m^2 - 2wm) + K\\\\\n",
    "&= -\\frac{1}{2v}w^2 + \\frac{m}{v} w + K' \\tag{6}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Task 6**: By comparing the coefficients for $w$ and $w^2$ in eq. (5) and (6), show that the mean $\\hat{m}$ and variance $\\hat{v}$ of $q(w) = \\mathcal{N}(w|\\hat{m}, \\hat{w})$ are given by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{m} &=  \\frac{\\hat{v}}{\\sigma^2} \\hat{p} t \\tag{7}\n",
    "\\end{align*}\n",
    "$$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{v} &=\\frac{1}{\\frac{1}{\\sigma^2}\\hat{p} +  \\frac{1}{\\kappa^2}}\\tag{8}\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the optimal values for $\\hat{m}$ and $\\hat{v}$ depend on $\\hat{p}$, i.e. the variational parameter for $q(s)$.\n",
    "\n",
    "This concludes the calculation for $q(w) = \\mathcal{N}(w|\\hat{m}, \\hat{v})$. Let's do the same for $q(s)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: The optimal distribution for $q(s)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same strategy for $q(s)$ and now focus on terms that depends on $s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\ln q^*(s) &= \\mathbb{E}_{q(w)}\\left[ \\ln p(t|s, w)p(s)p(w)\\right] + K\\\\\n",
    "%\n",
    "&=  \\mathbb{E}_{q(w)}\\left[\\ln \\mathcal{N}(t|sw, \\sigma^2)\\text{Ber}(s|p_0)\\mathcal{N}(w|0, \\kappa^2)\\right] + K\\\\\n",
    "%\n",
    "&=  \\mathbb{E}_{q(w)}\\left[\\ln \\mathcal{N}(t|sw, \\sigma^2) \\right] + \\mathbb{E}_{q(w)}\\left[\\ln \\text{Ber}(s|p_0)\\right] + \\mathbb{E}_{q(w)}\\left[ \\ln \\mathcal{N}(w|0, \\kappa^2)\\right] + K\\\\\n",
    "%\n",
    "&=  \\mathbb{E}_{q(w)}\\left[\\ln \\mathcal{N}(t|sw, \\sigma^2) \\right] + \\ln \\text{Ber}(s|p_0) + K',\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where we have absorbed to term $\\mathbb{E}_{q(w)}\\left[ \\ln  \\mathcal{N}(w|0, \\kappa^2)\\right]$ into the constant because it is independent of $s$.\n",
    "\n",
    "**Task 7**: Show that $\\ln q^*(s)$ is given by\n",
    "\n",
    "\\begin{align*}\n",
    "\\ln q^*(s) &= -s^2\\frac{1}{2\\sigma^2}\\left[\\hat{m}^2 + \\hat{v}\\right] + ts \\frac{1}{\\sigma^2}  \\hat{m} + (1-s)  \\ln(1-p_0) + s \\ln(p_0) + K \\tag{9}\n",
    "\\end{align*}\n",
    "\n",
    "*Hint*: The first two moments of a Gaussian are $\\mathbb{E}_{q(w)}\\left[w\\right] = \\hat{m}$ and $\\mathbb{E}_{q(w)}\\left[w^2\\right] = \\hat{m}^2 + \\hat{v}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Normalizing the distribution $q^*(s)$***\n",
    "\n",
    "\n",
    "We can now calculate\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\ln q^*(s=0) &= \\ln(1-p_0) + K\\\\\n",
    "\\ln q^*(s=1) &= -\\frac{1}{2\\sigma^2}\\left[\\hat{m}^2 + \\hat{v}\\right] + t \\frac{1}{\\sigma^2}  \\hat{m} + \\ln(p_0) + K\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $q^*(s)$ is a Bernoulli distribution with parameter $\\hat{p}$ and $q^*(s=0) + q^*(s=1) = 1$, we know that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{p} = q^*(s=1) &= \\frac{q^*(s=1)}{q^*(s=0) + q^*(s=1)} \\tag{10}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Therefore, we can compute $\\hat{p}$ by exponentiating and summing over $s$ in eq. (9) to normalize it.\n",
    "Again, we notice that the optimal value for $\\hat{p}$ depends on the variational parameters of $q(w)$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3: Fixed-point algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a set of equations for $q(w)$ that depends on $q(s)$ and vice versa. \n",
    "We can now use eq. (7), (8), and (10) to implement a simple fixed-point algorithm for fitting the variational approximation. This means that we inialize $\\hat{p}$, $\\hat{m}$ and $\\hat{v}$ and we simply iterate the three equations until we reach convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8**: Complete the function *fit_approximation* below using eq. (7), (8) and (10).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 27 iterations\n"
     ]
    }
   ],
   "source": [
    "def fit_approximation(t, p0, sigma2, kappa2, max_itt=50, conv_tol=1e-12, verbose=False):\n",
    "    \"\"\" implements a fixed point algorithm for estimating phat, mhat and vhat\n",
    "\n",
    "        The function iterates the update equations (7), (8) and (10) for a maximum of max_itt iterations or until a convergece tolerance of conv_tol is reached.\n",
    "        That is, we declare convergence of the sum of squares for the variational parameters between two consequtive iterations is below conv_tol.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize variational parameters\n",
    "    mhat = 0\n",
    "    vhat = 1\n",
    "    phat = 0.5\n",
    "    \n",
    "    # for convergence testing\n",
    "    old_values = np.array([mhat, vhat, phat])\n",
    "    \n",
    "    # iterate\n",
    "    for itt in range(max_itt):\n",
    "                \n",
    "        # updaet vhat\n",
    "        vhat = ?\n",
    "        \n",
    "        # update mhat?\n",
    "        mhat = ?\n",
    "        \n",
    "        # update phat\n",
    "        phat = ?\n",
    "        \n",
    "        # check convergence\n",
    "        values = np.array([mhat, vhat, phat])\n",
    "        if np.sum((values-old_values)**2) < conv_tol:\n",
    "            if verbose:\n",
    "                print('Converged in %d iterations' % itt)\n",
    "            break\n",
    "        \n",
    "        old_values = values\n",
    "\n",
    "    return phat, mhat, vhat\n",
    "        \n",
    "t = 0.1    \n",
    "    \n",
    "phat, mhat, vhat = fit_approximation(t, p0=0.5, sigma2=0.1, kappa2=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4: Comparing the approximation to the exact posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Task 9***: Repeat the plots from Part 1.3, but compute and plot the the variational approximation $q(s)$ on top. Repeat the plot for $p_0 \\in \\left\\lbrace 0.1, 0.5, 0.9\\right\\rbrace$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "1) Comment on the quality of the approximation. Is it equally good for all values of $t$ and $p_0$?\n",
    "\n",
    "2) Use to figures to argue that the variational approximation is **over-confident**\n",
    "\n",
    "*Hints*\n",
    "1. What happens near $t = 0$ for $p_0 = 0.1$ and for $p_0 = 0.9$?\n",
    "2. When do we have most uncertainty for a binary random variable, i.e. when is the variance or entropy maximized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: The evidence lower bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evidence lower bound (ELBO) $\\mathcal{L}\\left[q\\right]$ is a central quantity in variational inference and is defined as\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(q) = \\mathbb{E}_q\\left[\\ln p(t, s, w)\\right] - \\mathbb{E}_q\\left[\\ln q(s, w)\\right],\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "In practice, we will often optimize this quantity directly as we will see next week.\n",
    "\n",
    "Recall the relationship\n",
    "\n",
    "$$\n",
    "\\ln p(t) = \\text{KL}[q||p] + \\mathcal{L}(q) \\geq \\mathcal{L}(q)\n",
    "$$\n",
    "\n",
    "and the fact that ELBO is a lower bound on the log marginal likelihood. For this reason the ELBO is also often used for hyperparameter tuning. Let $\\theta = \\left(\\sigma^2, \\kappa^2, p_0\\right)$ denote the hyperparameters of the model then we can write\n",
    "\n",
    "$$\n",
    "\\log p(t|\\theta) \\geq \\mathcal{L}_{\\theta}(q)\n",
    "$$\n",
    "\n",
    "and thus, simply maximizing $\\mathcal{L}_{\\theta}(q)$ wrt. $\\theta$ works well in practice for many models. \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The evidence lower bound for this model can be found by a rather long, but somewhat straight-forward calculation\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}\\left[q\\right] &= \\mathbb{E}_{q(s)q(w)} \\left[\\ln p(t|s, w)p(s)p(w) \\right] - \\mathbb{E}_{q(s)q(w)} \\left[ \\ln q(s)q(w) \\right]\\\\\n",
    "%\n",
    "&= \\mathbb{E}_{q(s)q(w)} \\left[\\ln p(t|s, w) \\right] + \\mathbb{E}_{q(s)q(w)} \\left[ \\ln p(s) \\right] + \\mathbb{E}_{q(s)q(w)} \\left[ \\ln p(w) \\right] - \\mathbb{E}_{q(s)q(w)} \\left[ \\ln q(s) \\right] -  \\mathbb{E}_{q(s)q(w)} \\left[ q(w) \\right]\\\\\n",
    "%\n",
    "&= \\mathbb{E}_{q(s)q(w)} \\left[\\ln p(t|s, w) \\right] + \\mathbb{E}_{q(s)} \\left[ \\ln \n",
    "p(s) \\right] + \\mathbb{E}_{q(w)} \\left[ \\ln p(w) \\right] - \\mathbb{E}_{q(s)} \\left[ \\ln q(s) \\right] -  \\mathbb{E}_{q(w)} \\left[ \\ln q(w) \\right]\\\\\n",
    "%\n",
    "&=  \\underbrace{-\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(t^2 + \\hat{p}(\\hat{m}^2 + \\hat{v})-2t\\hat{p}\\hat{m})}_{\\mathbb{E}_{q(s)q(w)} \\left[\\ln p(t|s, w) \\right]}\n",
    "%\n",
    "+ \\underbrace{(1-\\hat{p})\\ln(1-p_0) + \\hat{p}\\ln(p_0)}_{- \\mathbb{E}_{q(s)q(w)} \\left[ \\ln q(s)q(w) \\right]}\n",
    "%\n",
    " \\underbrace{-\\frac{1}{2}\\ln(2\\pi\\kappa^2) - \\frac{1}{2\\kappa^2}\\left(\\hat{m}^2 + \\hat{v}\\right)}_{\\mathbb{E}_{q(s)q(w)} \\left[ \\ln p(w) \\right] }\n",
    " %\n",
    " \\underbrace{- (1-\\hat{p})\\ln(1-\\hat{p}) - \\hat{p}\\ln(\\hat{p})}_{- \\mathbb{E}_{q(s)q(w)} \\left[ \\ln q(s) \\right]}\n",
    " %\n",
    " %\n",
    "+ \\underbrace{\\frac{1}{2}\\ln(2\\pi e\\hat{v})}_{-  \\mathbb{E}_{q(w)} \\left[ \\ln q(w) \\right]}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "You should be able to carry out calculations like this by now, but such calculations does require a decent amount of time to do and therefore, we have provided all the details for this calculation as an appendix by the end of the notebook to save you the time. If you are curious or not sure how to do such calculations, we suggest that you study the calculations below and feel free to ask questions about the details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Evaluating the lower bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bernoulli_entropy(p):\n",
    "    \"\"\" computes the entropy of a Bernoulli random variable Ber(p) \"\"\"\n",
    "    return ?\n",
    "\n",
    "def gauss_entropy(m, v):\n",
    "    \"\"\" computes the entropy of a Gaussian random variable N(m, v) \"\"\"\n",
    "    return ?\n",
    "\n",
    "\n",
    "def evaluate_elbo(t, phat, mhat, vhat):\n",
    "    \n",
    "    t1 = -0.5*np.log(2*np.pi*sigma2) - 1/(2*sigma2)*(t**2 + mhat**2*phat+vhat*phat - 2*t*mhat*phat )\n",
    "    t2 = (1-phat)*np.log(1-p0) + phat*np.log(p0)\n",
    "    t3 = -0.5*np.log(2*np.pi*kappa2) - 1/(2*kappa2)*(mhat**2 + vhat)\n",
    "    t4 = bernoulli_entropy(phat)\n",
    "    t5 = gauss_entropy(mhat, vhat)\n",
    "    \n",
    "    return t1+t2+t3+t4+t5\n",
    "\n",
    "# data and hyperparameters\n",
    "sigma2 = 0.1\n",
    "kappa2 = 1\n",
    "p0 = 0.2\n",
    "t = 1\n",
    "\n",
    "# evaluate ELBO as a function of iterations\n",
    "max_itt = 10\n",
    "elbos = np.zeros(max_itt)\n",
    "for itt in range(max_itt):\n",
    "    phat, mhat, vhat = fit_approximation(t, p0, sigma2, kappa2, max_itt=itt, conv_tol=1e-10)\n",
    "    elbos[itt] = evaluate_elbo(t, phat, mhat, vhat)\n",
    "\n",
    "# compute exact marginal likelihood\n",
    "log_exact = np.log(marginal_likelihood(t, p0, sigma2, kappa2))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "axes[0].plot(elbos, label='lowerbound $\\mathcal{L}$')\n",
    "axes[0].set(xlabel='Iterations', ylabel='ELBO', title='ELBO vs iterations')\n",
    "axes[0].axhline(log_exact, linestyle='--', color='g', label='Exact marginal likelihood')\n",
    "axes[0].legend()\n",
    "axes[1].plot(log_exact - elbos)\n",
    "axes[1].set(xlabel='Iterations', ylabel='KL Divergence', title='KL divergence vs iterations', ylim=(-0.5, 10));\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Task 11***: Complete the implementation of the two functions for computing the entropy a Bernoulli and a Gaussian random variable above.\n",
    "\n",
    "**Questions**\n",
    "\n",
    "1) Explain what you see in the figure. What is the relationship between the blue curves in the two plots?\n",
    "\n",
    "2) How is the KL divergence computed? and why can we do this in this example?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Complete calculation of ELBO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The evidence lower bound for this model can be found by a rather long, but straight-forward calculation\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}\\left[q\\right] &= \\mathbb{E}_{q(s)q(w)} \\left[\\ln p(t|s, w)p(s)p(w) \\right] - \\mathbb{E}_{q(s)q(w)} \\left[ \\ln q(s)q(w) \\right]\\\\\n",
    "%\n",
    "&= \\mathbb{E}_{q(s)q(w)} \\left[\\ln p(t|s, w) \\right] + \\mathbb{E}_{q(s)q(w)} \\left[ \\ln p(s) \\right] + \\mathbb{E}_{q(s)q(w)} \\left[ \\ln p(w) \\right] - \\mathbb{E}_{q(s)q(w)} \\left[ \\ln q(s) \\right] -  \\mathbb{E}_{q(s)q(w)} \\left[ q(w) \\right]\\\\\n",
    "%\n",
    "&= \\mathbb{E}_{q(s)q(w)} \\left[\\ln p(t|s, w) \\right] + \\mathbb{E}_{q(s)} \\left[ \\ln \n",
    "p(s) \\right] + \\mathbb{E}_{q(w)} \\left[ \\ln p(w) \\right] - \\mathbb{E}_{q(s)} \\left[ \\ln q(s) \\right] -  \\mathbb{E}_{q(w)} \\left[ \\ln q(w) \\right]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The terms $- \\mathbb{E}_{q(s)} \\left[ \\ln q(s) \\right]$ and $-  \\mathbb{E}_{q(w)} \\left[ \\ln q(w) \\right]$ are the **entropy** of $q(s)$ and $q(w)$, respectively.\n",
    "\n",
    "Let's calculate all terms. The first term\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}_{q(s)q(w)} \\left[\\ln p(t|s, w) \\right] &= \\mathbb{E}_{q(s)q(w)} \\left[-\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(t-sw)^2 \\right]\\\\\n",
    "%\n",
    "&= \\mathbb{E}_{q(s)q(w)} \\left[-\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(t^2 + s^2w^2-2tsw) \\right]\\\\\n",
    "%\n",
    "&= \\mathbb{E}_{q(s)q(w)} \\left[-\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(t^2 + s^2w^2-2tsw) \\right]\\\\\n",
    "%t\n",
    "&= -\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(t^2 + \\mathbb{E}_{q(s)} \\left[s^2\\right]\\mathbb{E}_{q(w)} \\left[w^2\\right]-2t\\mathbb{E}_{q(s)} \\left[s\\right]\\mathbb{E}_{q(w)} \\left[w\\right])\\\\\n",
    "%\n",
    "&= -\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(t^2 + \\hat{p}(\\hat{m}^2 + \\hat{v})-2t\\hat{p}\\hat{m})\\\\\n",
    "%\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second term\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " \\mathbb{E}_{q(s)} \\left[ \\ln p(s) \\right] = q(s=0)\\ln p(s=0) + q(s=1) \\ln p(s=1) &= (1-\\hat{p})\\ln(1-p_0) + \\hat{p}\\ln(p_0)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third term\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    " \\mathbb{E}_{q(w)} \\left[ \\ln p(w) \\right] &= \\mathbb{E}_{q(w)} \\left[ -\\frac{1}{2}\\ln(2\\pi\\kappa^2) - \\frac{1}{2\\kappa^2}w^2\\right]\\\\\n",
    " %\n",
    " &=   -\\frac{1}{2}\\ln(2\\pi\\kappa^2) - \\frac{1}{2\\kappa^2}\\mathbb{E}_{q(w)} \\left[w^2\\right]\\\\\n",
    " %\n",
    " &=   -\\frac{1}{2}\\ln(2\\pi\\kappa^2) - \\frac{1}{2\\kappa^2}\\left(\\hat{m}^2 + \\hat{v}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The fourth term (-negative entropy of $q(s)$) is given by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    " \\mathbb{E}_{q(s)} \\left[ \\ln q(s) \\right] = q(s=0)\\ln q(s=0) + q(s=1) \\ln q(s=1) &= (1-\\hat{p})\\ln(1-\\hat{p}) + \\hat{p}\\ln(\\hat{p})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The last term is the (negative) posterior entropy of $w$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    " \\mathbb{E}_{q(w)} \\left[ \\ln q(w) \\right] &= \\mathbb{E}_{q(w)} \\left[ -\\frac{1}{2}\\ln(2\\pi\\hat{v}) - \\frac{1}{2\\hat{v}}(w-\\hat{m})^2\\right]\\\\\n",
    " %\n",
    " &= -\\frac{1}{2}\\ln(2\\pi\\hat{v}) - \\frac{1}{2\\hat{v}} \\mathbb{E}_{q(w)} \\left[(w-\\hat{m})^2\\right]\\\\\n",
    " %\n",
    " &= -\\frac{1}{2}\\ln(2\\pi\\hat{v}) - \\frac{1}{2\\hat{v}} \\mathbb{E}_{q(w)} \\left[w^2 + \\hat{m}^2 - 2w\\hat{m}\\right]\\\\\n",
    " %\n",
    " &= -\\frac{1}{2}\\ln(2\\pi\\hat{v}) - \\frac{1}{2\\hat{v}}  \\left(\\hat{m}^2 + \\hat{v} + \\hat{m}^2 - 2\\hat{m}^2\\right)\\\\\n",
    " %\n",
    " &= -\\frac{1}{2}\\ln(2\\pi\\hat{v}) - \\frac{1}{2}\\\\\n",
    " %\n",
    " &= -\\frac{1}{2}\\ln(2\\pi\\hat{v}) - \\frac{1}{2}\\ln(e)\\\\\n",
    " &= -\\frac{1}{2}\\ln(2\\pi e\\hat{v})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting everything together yields\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}\\left[q\\right] &= -\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(t^2 + \\hat{p}(\\hat{m}^2 + \\hat{v})-2t\\hat{p}\\hat{m}) + (1-\\hat{p})\\ln(1-p_0) + \\hat{p}\\ln(p_0)  -\\frac{1}{2}\\ln(2\\pi\\kappa^2) - \\frac{1}{2\\kappa^2}\\left(\\hat{m}^2 + \\hat{v}\\right) - (1-\\hat{p})\\ln(1-\\hat{p}) - \\hat{p}\\ln(\\hat{p}) + \\frac{1}{2}\\ln(2\\pi e\\hat{v})\n",
    "\\end{align*}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
